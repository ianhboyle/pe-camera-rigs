# Canon RF 5.2mm Dual Fisheye - Real User Insights

**Research Date:** 2025-12-07
**Purpose:** Learn from real Canon VR180 users to optimize Blender workflow

---

## Overview

Analysis of real-world Canon RF 5.2mm f/2.8 L Dual Fisheye user experiences, workflows, and pain points to inform our Blender VR180 implementation. We can solve many of their problems and learn from their best practices.

---

## Canon EOS VR Workflow (Their Process)

### Step 1: Capture
- Shoot with Canon R5/R5C + RF 5.2mm Dual Fisheye lens
- Records side-by-side fisheye to single sensor (no stitching needed)
- Outputs Canon RAW (CRM) or H.265 files
- Uses camera's gyroscope for stabilization data

### Step 2: Convert (EOS VR Utility)
- **Software:** Canon EOS VR Utility or Adobe Premiere Plugin
- **Process:** Convert fisheye to equirectangular SBS
- **Output:** Apple ProRes 422/4444 or HEVC 4:4:4 10-bit

### Step 3: Edit
- Import into DaVinci Resolve, Premiere Pro, or Final Cut Pro
- Color grade (usually Canon Log 3)
- Edit timeline

### Step 4: Export & Upload
- Export as H.265 with VR180 metadata
- Upload to YouTube/Meta Quest

---

## Major Pain Points (What Users Struggle With)

### 1. Extremely Long Processing Times âš ï¸

**Problem:**
- 2-minute 8K RAW video = 50GB file
- Processing can take **9 hours on older computers**
- Even on fast machines: 20+ minutes for 2 minutes of footage
- 3-minute 8K RAW (43GB) â†’ 3+ hours conversion â†’ 100GB output

**User Quote:**
> "Close absolutely everything down before running VR Utilities - even having Chrome open makes things slower"

**Impact:**
- Workflow bottleneck
- Makes iteration slow
- Requires powerful computers
- Discourages experimentation

**ðŸŽ¯ Blender Advantage:**
We don't have this problem! Blender renders directly to final format with metadata injection. No separate conversion step needed.

---

### 2. Massive File Sizes

**Problem:**
- 2 minutes of 8K RAW = 50GB
- Converted files even larger (100GB+)
- Requires fast external drives
- USB drives too slow - need Thunderbolt

**User Recommendations:**
- 32GB RAM (16GB absolute minimum, not Canon's stated 8GB)
- Fast SSD storage (NVMe recommended)
- Close all background apps during processing

**ðŸŽ¯ Blender Advantage:**
We can render at final resolution directly to H.265, skipping intermediate ProRes step. Smaller files throughout workflow.

---

### 3. Required Corrections

Canon EOS VR Utility provides these corrections (users must manually enable):

#### Parallax Correction âœ… **Always Recommended**
- Uses computer vision to adjust pixel height between left/right eyes
- Compensates for minor lens misalignments
- **User advice:** Always check this option

**ðŸŽ¯ Blender Advantage:**
Perfect alignment by default (CG cameras always perfectly aligned). No correction needed!

#### Horizontal Leveling (Gyroscope Data)
- Uses camera's inertial sensor to level footage
- Fixes horizon tilt

**User feedback:**
> "A bubble level on a tripod may be more reliable than consumer-grade sensors"

**ðŸŽ¯ Blender Application:**
- We should add "level check" warning if camera isn't level
- Add visual indicator in viewport (horizon line)
- Make keeping camera level easier

#### Chromatic Aberration Correction
- Removes purple/green fringing from lens
- Requires R5 C firmware 1.0.7.1+
- Bug in EOS VR Utility 1.4.0 (must process clips individually)

**ðŸŽ¯ Blender Advantage:**
CG doesn't have chromatic aberration! Perfectly clean images. No correction needed.

#### Image Stabilization
- Turn OFF for tripod footage
- Turn ON (trackability mode) for gimbal footage

**ðŸŽ¯ Blender Application:**
- We don't need stabilization (CG is always stable)
- But we can add camera shake simulation if desired

---

### 4. Metadata Injection Challenges

**Problem:**
- Users must manually mark footage as "VR180 stereoscopic side-by-side"
- Metadata must be burned into file before YouTube upload
- If missed, video displays as flat 2D

**Workflow:**
1. Export from editor
2. Open in Spatial Media Metadata Injector
3. Check "180Â°" and "Stereoscopic 3D (left-right)"
4. Save new file with metadata
5. Upload to YouTube

**ðŸŽ¯ Blender Advantage:**
**We solve this completely!** Our automated metadata injection means users never have to think about it. One-click export to YouTube-ready file.

---

### 5. Software Ecosystem Lock-In

**Problem:**
- Requires Canon EOS VR Utility (proprietary)
- Or Adobe Premiere Plugin (Adobe ecosystem only)
- Can't edit raw fisheye in DaVinci/Premiere/FCP directly
- Premiere Plugin often doesn't work or crashes

**User frustrations:**
- Plugin not registering with R5 C
- Crashes and errors
- Limited to Adobe ecosystem

**ðŸŽ¯ Blender Advantage:**
Open-source, cross-platform, no proprietary lock-in. Works on Windows, Mac, Linux.

---

## Best Practices (What Works Well)

### Optimal Subject Distance: 3-15 feet

**User recommendation:**
> "Subjects generally look best positioned between 3 and 15 feet from the camera - close enough to engage with but far enough to look pleasing"

**Why:**
- **Too close (<3ft):** Excessive parallax, eye strain, unnatural depth
- **3-15ft (sweet spot):** Natural depth, comfortable viewing, engaging
- **Too far (>15ft):** Depth becomes less noticeable, loses 3D effect

**ðŸŽ¯ Blender Application:**
- Add subject distance guidelines to docs
- Include "comfort zone" visual indicator in viewport
- Suggest optimal camera-to-subject distances in presets
- Add IPD adjustment recommendations based on distance

---

### Camera Settings (Real-World)

**From Canon Users:**

**For R7 + RF-S 3.9mm:**
- 4K 30p (highest image quality)
- HDR PQ disabled with dual fisheye lens

**For R5/R5C:**
- 8K RAW for maximum quality (but huge files)
- Canon Log 3 gamma (NOT Canon Log 2)
- Record gyroscope data for stabilization

**ðŸŽ¯ Blender Application:**
- Our default: 5.7K (2880Ã—2880 per eye) @ 60fps
- Offer 4K, 5.7K, 8K presets
- Color space: sRGB default, Canon Log 3 option for matching real footage

---

### Post-Processing Workflow

**What works:**
1. **Convert in batches** while sleeping/overnight
2. **Use proxies** for editing (lower res versions)
3. **Color grade in Log** then convert to Rec.709
4. **Export high bitrate** (100Mbps minimum for H.265)

**What doesn't work:**
- Trying to edit during conversion (slows everything)
- Using USB drives (too slow)
- Skipping metadata injection step

**ðŸŽ¯ Blender Application:**
- Render directly to final format (no conversion step)
- Optional proxy rendering for preview
- Built-in color management
- Automatic metadata injection

---

## Technical Specifications Used

### Resolution & Frame Rates

**Most Common:**
- 5.7K 30fps (R5)
- 8K 30fps (R5, R5C)
- 4K 60fps (when motion matters)

**YouTube Upload:**
- Usually 5.7K or 4K
- 8K often downsampled (file size/bandwidth)

**ðŸŽ¯ Blender Defaults:**
- 5.7K 60fps (YouTube optimal)
- 4K 60fps (Meta Quest optimal)
- 8K 30fps (archival quality)

### Encoding Settings

**From EOS VR Utility:**
- Output: Apple ProRes 422 HQ or ProRes 4444
- Color: Canon Log 3 or Rec.709
- Bitrate: Very high (ProRes is huge)

**For YouTube:**
- Final export: H.265/HEVC
- Bitrate: 100Mbps minimum
- Color: Rec.709 or Rec.2020

**ðŸŽ¯ Blender Direct Export:**
- Skip ProRes intermediate step
- Render directly to H.265 @ 100Mbps
- Huge time savings

---

## What Canon Users Would Love (That We Can Provide)

### 1. No Conversion Step âœ…
**Their problem:** Hours of conversion before editing
**Our solution:** Render directly to final format

### 2. Automatic Metadata âœ…
**Their problem:** Manual metadata injection required
**Our solution:** Automatic spatial metadata injection

### 3. Perfect Alignment âœ…
**Their problem:** Need parallax correction for lens misalignment
**Our solution:** Perfect CG camera alignment by default

### 4. No Chromatic Aberration âœ…
**Their problem:** Purple/green fringing needs correction
**Our solution:** Clean CG rendering (no lens artifacts)

### 5. Flexible Resolution âœ…
**Their problem:** Limited to camera sensor resolution
**Our solution:** Any resolution (4K, 5.7K, 8K, 12K+)

### 6. No File Size Issues âœ…
**Their problem:** 50-100GB files for minutes of footage
**Our solution:** Render directly to compressed format

### 7. Instant Preview âœ…
**Their problem:** Must process before seeing equirectangular
**Our solution:** Real-time compositor preview in Blender

### 8. Re-render Capability âœ…
**Their problem:** Can't change camera settings after capture
**Our solution:** Adjust IPD, FOV, resolution anytime and re-render

---

## Lessons Applied to Blender Workflow

### 1. Add Subject Distance Guidelines

**In Documentation:**
```
Optimal subject placement:
- Close shots: 3-5 feet (intimate, engaging)
- Medium shots: 5-10 feet (natural, comfortable)
- Wide shots: 10-15 feet (environmental, spatial)
- Avoid: <3 feet (eye strain) or >20 feet (minimal depth)
```

**In Add-on:**
- Distance measurement tool
- Visual "comfort zone" indicator
- IPD recommendations based on subject distance

---

### 2. Add Camera Level Check

**Visual Indicator:**
- Horizon line overlay in viewport
- Tilt angle display
- Warning if tilt >2Â° (motion sickness risk)

**Auto-Level Option:**
- Snap camera to level on creation
- Lock rotation X/Y, allow Z only (panning)

---

### 3. Color Space Options

**Presets:**
- sRGB (default, web/YouTube)
- Rec.709 (video standard)
- Canon Log 3 (match real Canon footage)
- ACES (high-end workflow)

**Use Case:**
Users mixing CG with real Canon footage need matching color spaces.

---

### 4. Emphasize Our Advantages

**Marketing Points:**
- âœ… No conversion step (save hours)
- âœ… No massive file sizes (direct H.265)
- âœ… Automatic metadata injection
- âœ… Perfect alignment (no corrections needed)
- âœ… Re-render anytime (change settings after "capture")
- âœ… Unlimited resolution (not sensor-limited)
- âœ… Free & open-source (no $2,000 camera needed)

---

### 5. Workflow Comparison

| Step | Canon Real Camera | Blender VR180 Add-on |
|------|-------------------|----------------------|
| **Capture** | Shoot with R5 + lens ($6,500) | Create scene in Blender (free) |
| **Convert** | 3-9 hours in EOS VR Utility | None needed âœ… |
| **File Size** | 50-100GB intermediate files | Direct to final size âœ… |
| **Corrections** | Parallax, aberration, level | None needed âœ… |
| **Edit** | Import ProRes, color grade | Optional editing |
| **Export** | Export H.265 from editor | Direct render to H.265 âœ… |
| **Metadata** | Manual injection with tool | Automatic âœ… |
| **Upload** | YouTube | YouTube |
| **Total Time** | 4-10+ hours | 30 min - 2 hours âœ… |

---

## Implementation Recommendations

### High Priority

1. **Subject Distance Guide:**
   - Add to documentation
   - Visual indicator in viewport (optional)
   - Recommended IPD adjustments for distance

2. **Camera Level Check:**
   - Warning if camera tilted
   - Visual horizon indicator
   - Auto-level option

3. **Color Space Presets:**
   - sRGB (default)
   - Canon Log 3 (match real footage)
   - Rec.709, Rec.2020, ACES

4. **Emphasize Speed Advantage:**
   - "No conversion step needed"
   - "Hours saved compared to real cameras"
   - Workflow comparison chart in docs

### Medium Priority

5. **Distance Measurement Tool:**
   - Show distance from camera to selected object
   - Color-code: green (3-15ft), yellow (<3ft or >15ft), red (<2ft)

6. **IPD Distance Advisor:**
   - Suggest IPD based on subject distance
   - Close objects â†’ 60-62mm
   - Medium â†’ 64mm
   - Distant â†’ 66-68mm

7. **Workflow Templates:**
   - "Interview Setup" (subject 5ft, 64mm IPD)
   - "Performance" (subject 10ft, 64mm IPD)
   - "Environmental" (15ft, 66mm IPD)

### Low Priority

8. **Canon Log 3 LUT:**
   - Optional LUT for Canon Log 3 look
   - For users mixing CG with Canon footage

---

## Sources & References

- [Canon EOS R5 C & Dual Fisheye Best Practices - Anthony MaÃ«s (Medium)](https://medium.com/@portemantho/canon-eos-r5-c-dual-fisheye-lens-best-practices-in-eos-vr-utility-ad9564ebda3a)
- [Post-processing VR 180 with Canon R5C - DIY Photography](https://www.diyphotography.net/post-processing-a-vr-180-video-with-the-canon-r5c-and-dual-fisheye-lens/)
- [Beginner's Guide to VR Filmmaking - Canon RF 5.2mm - Fstoppers](https://fstoppers.com/gear/beginners-guide-virtual-reality-filmmaking-canon-rf-52mm-f28-l-dual-fisheye-3d-638835)
- [Editing VR180 from Canon EOS R7 - postPerspective](https://postperspective.com/editing-vr180-content-from-canons-eos-r7-part-2/)
- [Canon Dual Fisheye Workflow Discussion - MacRumors Forums](https://forums.macrumors.com/threads/canon-dual-fisheye-lenses-video-workflow-project-in-progress.2444020/)

---

## Key Takeaways

1. **We solve their biggest pain point:** No conversion step, automatic metadata
2. **We have technical advantages:** Perfect alignment, no lens artifacts, unlimited resolution
3. **We should add their best practices:** Subject distance guidelines (3-15ft sweet spot)
4. **We can be faster:** Direct render vs hours of conversion
5. **We're more flexible:** Change any setting and re-render

**Our workflow is objectively better for CG VR180 content!**

The only advantage real cameras have: capturing real-world footage. For everything else (CG, animation, visualization), Blender VR180 workflow is superior.
